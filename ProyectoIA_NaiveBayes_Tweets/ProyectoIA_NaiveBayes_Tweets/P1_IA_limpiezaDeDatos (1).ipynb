{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8sApJg_m2jd",
        "outputId": "7bd3a7c6-84af-4aee-81b8-4ed8ab0e965f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset limpio y dividido guardado como .pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Cargar el dataset\n",
        "df = pd.read_csv('/content/twitter_training.csv', header=None)\n",
        "df.columns = ['ID', 'Entity', 'Sentiment', 'Content']\n",
        "\n",
        "# Filtrar solo sentimientos válidos\n",
        "df = df[df['Sentiment'].isin(['Positive', 'Negative', 'Neutral'])]\n",
        "\n",
        "# Normalizar sentimiento\n",
        "df['Sentiment'] = df['Sentiment'].str.lower()\n",
        "\n",
        "# Función de limpieza segura\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)  # quitar URLs\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)     # quitar menciones\n",
        "    text = re.sub(r\"#\\w+\", \"\", text)     # quitar hashtags\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # quitar puntuación\n",
        "    text = re.sub(r\"\\d+\", \"\", text)      # quitar números\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # quitar espacios múltiples\n",
        "    return text\n",
        "\n",
        "# Aplicar limpieza a valores no nulos\n",
        "df['Cleaned_Content'] = df['Content'].fillna(\"\").apply(clean_text)\n",
        "\n",
        "\n",
        "# Dividir datos\n",
        "train_df, test_df = train_test_split(df[['Cleaned_Content', 'Sentiment']], test_size=0.3, stratify=df['Sentiment'], random_state=42)\n",
        "\n",
        "# Guardar en Pickle\n",
        "with open('/content/cleaned_train.pkl', 'wb') as f:\n",
        "    pickle.dump(train_df, f)\n",
        "\n",
        "with open('/content/cleaned_test.pkl', 'wb') as f:\n",
        "    pickle.dump(test_df, f)\n",
        "\n",
        "print(\"Dataset limpio y dividido guardado como .pkl\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
